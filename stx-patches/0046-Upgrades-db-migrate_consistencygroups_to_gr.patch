From 76d6f654969317119186d80219436ffc0f84ce47 Mon Sep 17 00:00:00 2001
From: Daniel Badea <daniel.badea@windriver.com>
Date: Fri, 2 Feb 2018 11:07:17 +0000
Subject: [PATCH 46/53] Upgrades db migrate_consistencygroups_to_groups

While rebasing from Newton to Pike we skipped DB online migrations needed
by Ocata and as a result cinder reports warnings/errors when migrating
from R4 to R5.

This adds back support for migration from consistency groups in Newton
to groups in Ocata. Because the database model has changed from Ocata
to Pike the add_replication_status_to_groups_table script had to  be
moved to slot 92. Otherwise the online migration code fails because it
runs an invalid db query.
---
 cinder/cmd/manage.py                               |   4 +-
 cinder/db/api.py                                   |   5 +
 cinder/db/sqlalchemy/api.py                        | 146 ++++++++++++++
 .../092_add_replication_status_to_groups_table.py  |  28 +++
 .../migrate_repo/versions/092_placeholder.py       |  22 --
 .../102_add_replication_status_to_groups_table.py  |  28 ---
 .../migrate_repo/versions/102_placeholder.py       |  22 ++
 cinder/tests/unit/test_db_api.py                   | 223 +++++++++++++++++++++
 8 files changed, 427 insertions(+), 51 deletions(-)
 create mode 100644 cinder/db/sqlalchemy/migrate_repo/versions/092_add_replication_status_to_groups_table.py
 delete mode 100644 cinder/db/sqlalchemy/migrate_repo/versions/092_placeholder.py
 delete mode 100644 cinder/db/sqlalchemy/migrate_repo/versions/102_add_replication_status_to_groups_table.py
 create mode 100644 cinder/db/sqlalchemy/migrate_repo/versions/102_placeholder.py

diff --git a/cinder/cmd/manage.py b/cinder/cmd/manage.py
index e3a8255..145cda5 100644
--- a/cinder/cmd/manage.py
+++ b/cinder/cmd/manage.py
@@ -205,7 +205,9 @@ class HostCommands(object):
 class DbCommands(object):
     """Class for managing the database."""
 
-    online_migrations = ()
+    online_migrations = (
+        db.migrate_consistencygroups_to_groups,
+    )
 
     def __init__(self):
         pass
diff --git a/cinder/db/api.py b/cinder/db/api.py
index c850aa7..eff374a 100644
--- a/cinder/db/api.py
+++ b/cinder/db/api.py
@@ -1494,6 +1494,11 @@ def group_volume_type_mapping_create(context, group_id, volume_type_id):
                                                  volume_type_id)
 
 
+def migrate_consistencygroups_to_groups(context, max_count, force=False):
+    """Migrage CGs to generic volume groups"""
+    return IMPL.migrate_consistencygroups_to_groups(context, max_count, force)
+
+
 ###################
 
 
diff --git a/cinder/db/sqlalchemy/api.py b/cinder/db/sqlalchemy/api.py
index 5335f9a..9ad03a5 100644
--- a/cinder/db/sqlalchemy/api.py
+++ b/cinder/db/sqlalchemy/api.py
@@ -60,6 +60,7 @@ from cinder import exception
 from cinder.i18n import _
 from cinder.objects import fields
 from cinder import utils
+from cinder.volume import group_types
 from cinder.volume import utils as vol_utils
 
 
@@ -6050,6 +6051,151 @@ def group_creating_from_src(group_id=None, group_snapshot_id=None):
     return sql.exists([subq]).where(match_id)
 
 
+@require_admin_context
+def migrate_consistencygroups_to_groups(context, max_count, force=False):
+    now = timeutils.utcnow()
+    grps = model_query(context, models.Group)
+    ids = [grp.id for grp in grps] if grps else []
+    # NOTE(xyang): We are using the same IDs in the CG and Group tables.
+    # This is because we are deleting the entry from the CG table after
+    # migrating it to the Group table. Also when the user queries a CG id,
+    # we will display it whether it is in the CG table or the Group table.
+    # Without using the same IDs, we'll have to add a consistencygroup_id
+    # column in the Group group to correlate it with the CG entry so we
+    # know whether it has been migrated or not. It makes things more
+    # complicated especially because the CG entry will be removed after
+    # migration.
+    query = (model_query(context, models.ConsistencyGroup).
+             filter(models.ConsistencyGroup.id.notin_(ids)))
+    cgs = query.limit(max_count)
+
+    # Check if default group_type for migrating cgsnapshots exists
+    result = (model_query(context, models.GroupTypes,
+                          project_only=True).
+              filter_by(name=group_types.DEFAULT_CGSNAPSHOT_TYPE).
+              first())
+    if not result:
+        msg = (_('Group type %s not found. Rerun migration script to create '
+                 'the default cgsnapshot type.') %
+               group_types.DEFAULT_CGSNAPSHOT_TYPE)
+        raise exception.NotFound(msg)
+    grp_type_id = result['id']
+
+    count_all = 0
+    count_hit = 0
+    for cg in cgs.all():
+        cg_ids = []
+        cgsnapshot_ids = []
+        volume_ids = []
+        snapshot_ids = []
+        session = get_session()
+        with session.begin():
+            count_all += 1
+            cgsnapshot_list = []
+            vol_list = []
+
+            # NOTE(dulek): We should avoid modifying consistency groups that
+            # are in the middle of some operation.
+            if not force:
+                if cg.status not in (fields.ConsistencyGroupStatus.AVAILABLE,
+                                     fields.ConsistencyGroupStatus.ERROR,
+                                     fields.ConsistencyGroupStatus.DELETING):
+                    continue
+
+            # Migrate CG to group
+            grp = model_query(context, models.Group,
+                              session=session).filter_by(id=cg.id).first()
+            if grp:
+                # NOTE(xyang): This CG is already migrated to group.
+                continue
+
+            values = {'id': cg.id,
+                      'created_at': now,
+                      'updated_at': now,
+                      'deleted': False,
+                      'user_id': cg.user_id,
+                      'project_id': cg.project_id,
+                      'host': cg.host,
+                      'cluster_name': cg.cluster_name,
+                      'availability_zone': cg.availability_zone,
+                      'name': cg.name,
+                      'description': cg.description,
+                      'group_type_id': grp_type_id,
+                      'status': cg.status,
+                      'group_snapshot_id': cg.cgsnapshot_id,
+                      'source_group_id': cg.source_cgid,
+                      }
+
+            mappings = []
+            for item in cg.volume_type_id.rstrip(',').split(','):
+                mapping = models.GroupVolumeTypeMapping()
+                mapping['volume_type_id'] = item
+                mapping['group_id'] = cg.id
+                mappings.append(mapping)
+
+            values['volume_types'] = mappings
+
+            grp = models.Group()
+            grp.update(values)
+            session.add(grp)
+            cg_ids.append(cg.id)
+
+            # Update group_id in volumes
+            vol_list = (model_query(context, models.Volume,
+                                    session=session).
+                        filter_by(consistencygroup_id=cg.id).all())
+            for vol in vol_list:
+                vol.group_id = cg.id
+                volume_ids.append(vol.id)
+
+            # Migrate data from cgsnapshots to group_snapshots
+            cgsnapshot_list = (model_query(context, models.Cgsnapshot,
+                                           session=session).
+                               filter_by(consistencygroup_id=cg.id).all())
+
+            for cgsnap in cgsnapshot_list:
+                grp_snap = (model_query(context, models.GroupSnapshot,
+                                        session=session).
+                            filter_by(id=cgsnap.id).first())
+                if grp_snap:
+                    # NOTE(xyang): This CGSnapshot is already migrated to
+                    # group snapshot.
+                    continue
+
+                grp_snap = models.GroupSnapshot()
+                values = {'id': cgsnap.id,
+                          'created_at': now,
+                          'updated_at': now,
+                          'deleted': False,
+                          'user_id': cgsnap.user_id,
+                          'project_id': cgsnap.project_id,
+                          'group_id': cg.id,
+                          'name': cgsnap.name,
+                          'description': cgsnap.description,
+                          'group_type_id': grp_type_id,
+                          'status': cgsnap.status, }
+                grp_snap.update(values)
+                session.add(grp_snap)
+                cgsnapshot_ids.append(cgsnap.id)
+
+                # Update group_snapshot_id in snapshots
+                snap_list = (model_query(context, models.Snapshot,
+                                         session=session).
+                             filter_by(cgsnapshot_id=cgsnap.id).all())
+                for snap in snap_list:
+                    snap.group_snapshot_id = cgsnap.id
+                    snapshot_ids.append(snap.id)
+
+            # Delete entries in CG and CGSnapshot tables
+            cg_cgsnapshot_destroy_all_by_ids(context, cg_ids, cgsnapshot_ids,
+                                             volume_ids, snapshot_ids,
+                                             session=session)
+
+            count_hit += 1
+
+    return count_all, count_hit
+
+
 ###############################
 
 
diff --git a/cinder/db/sqlalchemy/migrate_repo/versions/092_add_replication_status_to_groups_table.py b/cinder/db/sqlalchemy/migrate_repo/versions/092_add_replication_status_to_groups_table.py
new file mode 100644
index 0000000..08f367d
--- /dev/null
+++ b/cinder/db/sqlalchemy/migrate_repo/versions/092_add_replication_status_to_groups_table.py
@@ -0,0 +1,28 @@
+# Copyright (C) 2017 Dell Inc. or its subsidiaries.
+# All Rights Reserved.
+#
+#    Licensed under the Apache License, Version 2.0 (the "License"); you may
+#    not use this file except in compliance with the License. You may obtain
+#    a copy of the License at
+#
+#         http://www.apache.org/licenses/LICENSE-2.0
+#
+#    Unless required by applicable law or agreed to in writing, software
+#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+#    License for the specific language governing permissions and limitations
+#    under the License.
+
+from sqlalchemy import Column
+from sqlalchemy import MetaData, String, Table
+
+
+def upgrade(migrate_engine):
+    meta = MetaData()
+    meta.bind = migrate_engine
+
+    # Add replication_status column to groups table
+    table = Table('groups', meta, autoload=True)
+    if not hasattr(table.c, 'replication_status'):
+        new_column = Column('replication_status', String(255), nullable=True)
+        table.create_column(new_column)
diff --git a/cinder/db/sqlalchemy/migrate_repo/versions/092_placeholder.py b/cinder/db/sqlalchemy/migrate_repo/versions/092_placeholder.py
deleted file mode 100644
index 7f0c9af..0000000
--- a/cinder/db/sqlalchemy/migrate_repo/versions/092_placeholder.py
+++ /dev/null
@@ -1,22 +0,0 @@
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-# This is a placeholder for Mitaka backports.
-# Do not use this number for new Newton work.  New work starts after
-# all the placeholders.
-#
-# See this for more information:
-# http://lists.openstack.org/pipermail/openstack-dev/2013-March/006827.html
-
-
-def upgrade(migrate_engine):
-    pass
diff --git a/cinder/db/sqlalchemy/migrate_repo/versions/102_add_replication_status_to_groups_table.py b/cinder/db/sqlalchemy/migrate_repo/versions/102_add_replication_status_to_groups_table.py
deleted file mode 100644
index 08f367d..0000000
--- a/cinder/db/sqlalchemy/migrate_repo/versions/102_add_replication_status_to_groups_table.py
+++ /dev/null
@@ -1,28 +0,0 @@
-# Copyright (C) 2017 Dell Inc. or its subsidiaries.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from sqlalchemy import Column
-from sqlalchemy import MetaData, String, Table
-
-
-def upgrade(migrate_engine):
-    meta = MetaData()
-    meta.bind = migrate_engine
-
-    # Add replication_status column to groups table
-    table = Table('groups', meta, autoload=True)
-    if not hasattr(table.c, 'replication_status'):
-        new_column = Column('replication_status', String(255), nullable=True)
-        table.create_column(new_column)
diff --git a/cinder/db/sqlalchemy/migrate_repo/versions/102_placeholder.py b/cinder/db/sqlalchemy/migrate_repo/versions/102_placeholder.py
new file mode 100644
index 0000000..7f0c9af
--- /dev/null
+++ b/cinder/db/sqlalchemy/migrate_repo/versions/102_placeholder.py
@@ -0,0 +1,22 @@
+#    Licensed under the Apache License, Version 2.0 (the "License"); you may
+#    not use this file except in compliance with the License. You may obtain
+#    a copy of the License at
+#
+#         http://www.apache.org/licenses/LICENSE-2.0
+#
+#    Unless required by applicable law or agreed to in writing, software
+#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+#    License for the specific language governing permissions and limitations
+#    under the License.
+
+# This is a placeholder for Mitaka backports.
+# Do not use this number for new Newton work.  New work starts after
+# all the placeholders.
+#
+# See this for more information:
+# http://lists.openstack.org/pipermail/openstack-dev/2013-March/006827.html
+
+
+def upgrade(migrate_engine):
+    pass
diff --git a/cinder/tests/unit/test_db_api.py b/cinder/tests/unit/test_db_api.py
index 0a8ace2..764b6aa 100644
--- a/cinder/tests/unit/test_db_api.py
+++ b/cinder/tests/unit/test_db_api.py
@@ -38,6 +38,7 @@ from cinder import quota
 from cinder import test
 from cinder.tests.unit import fake_constants as fake
 from cinder.tests.unit import utils
+from cinder.volume import group_types
 
 CONF = cfg.CONF
 THREE = 3
@@ -1917,6 +1918,228 @@ class DBAPIConsistencygroupTestCase(BaseTest):
                 db_cgs[i].cluster_name)
 
 
+class DBAPIMigrateCGstoGroupsTestCase(BaseTest):
+    """Tests for cinder.db.api.migrate_consistencygroups_to_groups."""
+
+    def setUp(self):
+        super(DBAPIMigrateCGstoGroupsTestCase, self).setUp()
+
+        db.volume_type_create(self.ctxt, {'id': 'a', 'name': 'a'})
+        db.volume_type_create(self.ctxt, {'id': 'b', 'name': 'b'})
+
+        cg_dicts = [
+            {'id': '1', 'status': fields.ConsistencyGroupStatus.AVAILABLE,
+             'volume_type_id': 'a,b,'},
+            {'id': '2', 'status': fields.ConsistencyGroupStatus.ERROR,
+             'volume_type_id': 'a,'},
+            {'id': '3',
+             'status': fields.ConsistencyGroupStatus.AVAILABLE,
+             'volume_type_id': 'b,'},
+            {'id': '4',
+             'status': fields.ConsistencyGroupStatus.UPDATING,
+             'volume_type_id': 'a,'},
+        ]
+        for cg_dict in cg_dicts:
+            db.consistencygroup_create(self.ctxt, cg_dict)
+
+        # Create volumes in CGs
+        self.vol1 = db.volume_create(self.ctxt, {'volume_type_id': 'a',
+                                                 'consistencygroup_id': '1',
+                                                 'status': 'available',
+                                                 'size': 1})
+        self.vol2 = db.volume_create(self.ctxt, {'volume_type_id': 'b',
+                                                 'consistencygroup_id': '1',
+                                                 'status': 'available',
+                                                 'size': 1})
+        self.vol3 = db.volume_create(self.ctxt, {'volume_type_id': 'b',
+                                                 'consistencygroup_id': '3',
+                                                 'status': 'available',
+                                                 'size': 1})
+
+        # Create cgsnapshots
+        cgsnap1 = db.cgsnapshot_create(
+            self.ctxt,
+            {'id': 'cgsnap1',
+             'consistencygroup_id': '1',
+             'status': fields.ConsistencyGroupStatus.AVAILABLE}
+        )
+        cgsnap3 = db.cgsnapshot_create(
+            self.ctxt,
+            {'id': 'cgsnap3',
+             'consistencygroup_id': '3',
+             'status': fields.ConsistencyGroupStatus.AVAILABLE}
+        )
+
+        # Create snapshots
+        self.snap1 = db.snapshot_create(
+            self.ctxt,
+            {'volume_id': self.vol1['id'],
+             'cgsnapshot_id': cgsnap1['id'],
+             'status': fields.SnapshotStatus.AVAILABLE})
+        self.snap2 = db.snapshot_create(
+            self.ctxt,
+            {'volume_id': self.vol2['id'],
+             'cgsnapshot_id': cgsnap1['id'],
+             'status': fields.SnapshotStatus.AVAILABLE})
+        self.snap3 = db.snapshot_create(
+            self.ctxt,
+            {'volume_id': self.vol3['id'],
+             'cgsnapshot_id': cgsnap3['id'],
+             'status': fields.SnapshotStatus.AVAILABLE})
+
+        # Create CG from CG snapshot
+        cg5_dict = {
+            'id': '5',
+            'cgsnapshot_id': cgsnap3['id'],
+            'status': fields.ConsistencyGroupStatus.AVAILABLE,
+            'volume_type_id': 'b,'
+        }
+        db.consistencygroup_create(self.ctxt, cg5_dict)
+        cg_dicts.append(cg5_dict)
+        self.vol5 = db.volume_create(self.ctxt, {'volume_type_id': 'b',
+                                                 'consistencygroup_id': '5',
+                                                 'status': 'available',
+                                                 'size': 1})
+
+        # Create CG from source CG
+        cg6_dict = {
+            'id': '6',
+            'source_cgid': '5',
+            'status': fields.ConsistencyGroupStatus.AVAILABLE,
+            'volume_type_id': 'b,'
+        }
+        db.consistencygroup_create(self.ctxt, cg6_dict)
+        cg_dicts.append(cg6_dict)
+        self.vol6 = db.volume_create(self.ctxt, {'volume_type_id': 'b',
+                                                 'consistencygroup_id': '6',
+                                                 'status': 'available',
+                                                 'size': 1})
+
+        self.addCleanup(self._cleanup)
+
+    def _cleanup(self):
+        db.snapshot_destroy(self.ctxt, self.snap1.id)
+        db.snapshot_destroy(self.ctxt, self.snap2.id)
+        db.snapshot_destroy(self.ctxt, self.snap3.id)
+
+        db.volume_destroy(self.ctxt, self.vol1.id)
+        db.volume_destroy(self.ctxt, self.vol2.id)
+        db.volume_destroy(self.ctxt, self.vol3.id)
+        db.volume_destroy(self.ctxt, self.vol5.id)
+        db.volume_destroy(self.ctxt, self.vol6.id)
+
+        db.cgsnapshot_destroy(self.ctxt, 'cgsnap1')
+        db.cgsnapshot_destroy(self.ctxt, 'cgsnap3')
+
+        db.group_snapshot_destroy(self.ctxt, 'cgsnap1')
+        db.group_snapshot_destroy(self.ctxt, 'cgsnap3')
+
+        db.consistencygroup_destroy(self.ctxt, '1')
+        db.consistencygroup_destroy(self.ctxt, '2')
+        db.consistencygroup_destroy(self.ctxt, '3')
+        db.consistencygroup_destroy(self.ctxt, '4')
+        db.consistencygroup_destroy(self.ctxt, '5')
+        db.consistencygroup_destroy(self.ctxt, '6')
+
+        db.group_destroy(self.ctxt, '1')
+        db.group_destroy(self.ctxt, '2')
+        db.group_destroy(self.ctxt, '3')
+        db.group_destroy(self.ctxt, '4')
+        db.group_destroy(self.ctxt, '5')
+        db.group_destroy(self.ctxt, '6')
+
+        db.volume_type_destroy(self.ctxt, 'a')
+        db.volume_type_destroy(self.ctxt, 'b')
+
+        grp_type = group_types.get_default_group_type()
+        if grp_type:
+            db.group_type_destroy(self.ctxt, grp_type.id)
+
+    def _assert_migrated(self, migrated, not_migrated):
+        for cg_id, cgsnap_id in migrated.items():
+            grp = db.group_get(self.ctxt, cg_id)
+            self.assertIsNotNone(grp)
+            vols_in_cgs = db.volume_get_all_by_group(self.ctxt, cg_id)
+            vols_in_grps = db.volume_get_all_by_generic_group(self.ctxt, cg_id)
+            self.assertEqual(0, len(vols_in_cgs))
+            if cg_id == '1':
+                self.assertEqual(2, len(vols_in_grps))
+            elif cg_id == '3':
+                self.assertEqual(1, len(vols_in_grps))
+            if cgsnap_id:
+                grp_snap = db.group_snapshot_get(self.ctxt, cgsnap_id)
+                self.assertIsNotNone(grp_snap)
+                snaps_in_cgsnaps = db.snapshot_get_all_for_cgsnapshot(
+                    self.ctxt, cgsnap_id)
+                snaps_in_grpsnaps = db.snapshot_get_all_for_group_snapshot(
+                    self.ctxt, cgsnap_id)
+                self.assertEqual(0, len(snaps_in_cgsnaps))
+                if cg_id == '1':
+                    self.assertEqual(2, len(snaps_in_grpsnaps))
+                elif cg_id == '3':
+                    self.assertEqual(1, len(snaps_in_grpsnaps))
+
+        for cg_id in not_migrated:
+            self.assertRaises(exception.GroupNotFound,
+                              db.group_get, self.ctxt, cg_id)
+
+    def test_migrate(self):
+        # Run migration
+        count_all, count_hit = db.migrate_consistencygroups_to_groups(
+            self.ctxt, 50)
+        # Check counted entries
+        self.assertEqual(6, count_all)
+        self.assertEqual(5, count_hit)
+
+        # Check migated
+        migrated = {'1': 'cgsnap1', '2': None, '3': 'cgsnap3',
+                    '5': None, '6': None}
+        not_migrated = ('4',)
+
+        self._assert_migrated(migrated, not_migrated)
+
+    def test_migrate_force(self):
+        # Run migration
+        count_all, count_hit = db.migrate_consistencygroups_to_groups(
+            self.ctxt, 50, True)
+        # Check counted entries
+        self.assertEqual(6, count_all)
+        self.assertEqual(6, count_hit)
+
+        # Check migrated
+        migrated = {'1': 'cgsnap1', '2': None, '3': 'cgsnap3', '4': None,
+                    '5': None, '6': None}
+
+        self._assert_migrated(migrated, ())
+
+    def test_migrate_limit_force(self):
+        # Run first migration
+        count_all, count_hit = db.migrate_consistencygroups_to_groups(
+            self.ctxt, 2, True)
+        # Check counted entries
+        self.assertEqual(2, count_all)
+        self.assertEqual(2, count_hit)
+
+        # Check migrated
+        migrated = {'1': 'cgsnap1', '2': None}
+        not_migrated = ('3', '4', '5', '6',)
+
+        self._assert_migrated(migrated, not_migrated)
+
+        # Run second migration
+        count_all, count_hit = db.migrate_consistencygroups_to_groups(
+            self.ctxt, 4, True)
+        # Check counted entries
+        self.assertEqual(4, count_all)
+        self.assertEqual(4, count_hit)
+
+        # Check migrated
+        migrated = {'1': 'cgsnap1', '2': None, '3': 'cgsnap3', '4': None,
+                    '5': None, '6': None}
+
+        self._assert_migrated(migrated, ())
+
+
 class DBAPICgsnapshotTestCase(BaseTest):
     """Tests for cinder.db.api.cgsnapshot_*."""
 
-- 
2.7.4

